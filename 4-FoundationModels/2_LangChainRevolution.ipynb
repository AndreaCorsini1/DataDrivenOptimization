{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlbz3_5-mllE"
   },
   "source": [
    "# Unlocking the Potential of Large Language Models with LangChain\n",
    "\n",
    "\n",
    "[LangChain](https://python.langchain.com/en/latest/getting_started/getting_started.html) is a widely used framework that enables users to easily develop applications and pipelines using Large Language Models (LLMs). With LangChain, you can create chatbots, Generative Question-Answering (GQA) systems, summarization tools, and much more.\n",
    "\n",
    "At the core of LangChain's design is the idea of \"chaining\" together different components to create more sophisticated LLM use-cases. These chains can comprise multiple components from various modules, including:\n",
    "\n",
    "  * ***Prompt Templates***: serve as pre-defined structures for different types of prompts such as chatbot-style interactions and more.\n",
    "\n",
    "  * ***Large Language Models***: LLMs such as GPT-3, BLOOM and Jurassic are used in LangChain to generate responses or perform language-related tasks.\n",
    "\n",
    "  * ***Agents***: utilize LLMs to determine the appropriate actions to take, using tools such as web search or calculators to execute operations within a logical loop.\n",
    "\n",
    "  * ***Memory***: LangChain provides both short-term and long-term memory to help LLMs retain information and improve their responses over time.\n",
    "\n",
    "With these modules, LangChain offers a comprehensive solution for developing advanced LLM-based applications that can enhance natural language processing in various fields.\n",
    "\n",
    "The following code downloads the necessary python libraries needed in this LAB, and then it load them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9g12MudNgIVd",
    "outputId": "81dc853f-b43e-45e4-a61a-34b5e9e6271a"
   },
   "outputs": [],
   "source": [
    "!pip install langchain==0.3.25\n",
    "!pip install langchain_community==0.3.24\n",
    "!pip install pypdf tiktoken numexpr transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQHXSQ54mKen"
   },
   "source": [
    "Afterwards, the API to the Large Language Models provided by [AI21](https://studio.ai21.com) is initizalized.\n",
    "\n",
    "> Go to the linked site and make an account. You have to insert your own API key provided in the site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "QzjiHjqZyDeF"
   },
   "outputs": [],
   "source": [
    "#import os\n",
    "\n",
    "#\n",
    "# !pip install langchain_ai21\n",
    "\n",
    "#\n",
    "# if \"AI21_API_KEY\" not in os.environ:\n",
    "#    os.environ[\"AI21_API_KEY\"] = \"put key here\"\n",
    "\n",
    "# from langchain_ai21 import ChatAI21\n",
    "# llm = ChatAI21(model=\"jamba-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make you key [here](https://console.groq.com/home) and paste it below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_base=\"https://api.groq.com/openai/v1\",\n",
    "    openai_api_key=\"your key here\",\n",
    "    model=\"llama3-8b-8192\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFzrLn5Y1Dnb"
   },
   "source": [
    "## Structure of a Prompt\n",
    "\n",
    "A prompt can consist of multiple components:\n",
    "\n",
    "* **Instructions** tell the model what to do, typically how it should use inputs and/or external information to produce the output we want.\n",
    "* **Additional information or context about the input** that is either manually insert into the prompt, retrieve via a vector database (long-term memory), or pull in through other means (API calls, calculations, etc).\n",
    "* **Output structure or indicators**, like how to frame the \\*beginning\\* of the generated text.\n",
    "\n",
    "Each of these components should usually be placed the order we've described them. We start with instructions, provide context (if needed), then add the user input, and finally end with the output indicators.\n",
    "\n",
    "Not all prompts require all of these components, but often a good prompt will use two or more of them. Let's define what they all are more precisely.\n",
    "\n",
    "### Adjust the tone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A neural network is a type of machine learning model inspired by the structure and function of the human brain. It is a complex system of interconnected nodes or \"neurons\" that process and transmit information. Neural networks are designed to recognize patterns and make decisions based on data, and they have become a crucial part of many artificial intelligence (AI) applications.\n",
      "\n",
      "A neural network typically consists of three types of layers:\n",
      "\n",
      "1. **Input layer**: This layer receives the input data, which can be images, sound waves, text, or any other type of data that can be represented as a numerical value.\n",
      "2. **Hidden layers**: These layers are where the \"magic\" happens. They are composed of multiple layers of interconnected nodes (neurons) that process and transform the input data. The nodes in each layer are connected to nodes in the previous and next layers, allowing the network to learn complex relationships between the input and output data.\n",
      "3. **Output layer**: This layer produces the final output of the network, which can be a classification label, a regression value, or any other type of output.\n",
      "\n",
      "The process of training a neural network involves feeding it a large dataset of examples, and adjusting the connections between nodes (weights and biases) to minimize the error between the network's predictions and the actual output. This is done using an optimization algorithm, such as stochastic gradient descent (SGD), and a loss function, such as mean squared error (MSE) or cross-entropy.\n",
      "\n",
      "Neural networks have many applications, including:\n",
      "\n",
      "1. **Image recognition**: Neural networks can be trained to recognize objects, faces, and patterns in images.\n",
      "2. **Natural language processing**: Neural networks can be used to process and understand natural language, such as speech or text.\n",
      "3. **Speech recognition**: Neural networks can be trained to recognize spoken words and phrases.\n",
      "4. **Game playing**: Neural networks can be used to play complex games, such as Go, chess, or poker.\n",
      "5. **Robotics**: Neural networks can be used to control robots and make decisions in real-time.\n",
      "\n",
      "Some of the key benefits of neural networks include:\n",
      "\n",
      "1. **Ability to learn**: Neural networks can learn from large datasets and improve their performance over time.\n",
      "2. **Ability to recognize complex patterns**: Neural networks can recognize complex patterns in data, such as images or speech.\n",
      "3. **Flexibility**: Neural networks can be used for a wide range of applications, from image recognition to natural language processing.\n",
      "4. **Scalability**: Neural networks can be trained on large datasets and scaled up to process large amounts of data.\n",
      "\n",
      "However, neural networks also have some limitations, including:\n",
      "\n",
      "1. **Interpretability**: Neural networks can be difficult to interpret, making it challenging to understand how they make decisions.\n",
      "2. **Overfitting**: Neural networks can overfit the training data, leading to poor performance on new, unseen data.\n",
      "3. **Requirements for large datasets**: Neural networks typically require large datasets to train, which can be time-consuming and expensive to collect.\n",
      "\n",
      "Overall, neural networks are a powerful tool for building AI applications, and they have many potential applications in fields such as healthcare, finance, and transportation.\n"
     ]
    }
   ],
   "source": [
    "question = \"What is a neural network?\"\n",
    "response = llm.invoke(question)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q) You are a professor giving a lecture to graduate students. Be precise and use formal academic language. Question: What is a neural network?\n",
      "\n",
      "Good morning, esteemed graduate students. Today, we will delve into the realm of artificial intelligence and explore the concept of neural networks.\n",
      "\n",
      "A neural network is a computational model inspired by the structure and function of the human brain. It is a type of machine learning algorithm that is composed of layers of interconnected nodes or \"neurons,\" which process and transmit information.\n",
      "\n",
      "The fundamental idea behind neural networks is that complex patterns in data can be learned by training a model on a large dataset. This is achieved through the interaction between neurons, which are arranged in a hierarchical manner, allowing the model to extract increasingly abstract representations of the input data.\n",
      "\n",
      "In more formal terms, a neural network can be defined as a directed graph G = (V, E), where V represents the set of neurons and E represents the set of directed edges connecting them. Each neuron v ∈ V is associated with a weight vector w_v and a bias term b_v. The output of each neuron is calculated using an activation function, typically a sigmoid or ReLU function, which maps the weighted sum of the inputs to a real-valued output.\n",
      "\n",
      "Formally, the output of a neuron v is given by:\n",
      "\n",
      "y_v = σ(w_v \\* x + b_v)\n",
      "\n",
      "where x is the input vector, σ is the activation function, and w_v and b_v are the weights and bias term, respectively.\n",
      "\n",
      "Neural networks can be used for a wide range of applications, including classification, regression, clustering, and dimensionality reduction. They have been particularly successful in image and speech recognition, natural language processing, and game playing.\n",
      "\n",
      "The key advantages of neural networks are their ability to:\n",
      "\n",
      "1. Learn complex patterns in data: Neural networks can learn complex relationships between input and output variables, even when these relationships are non-linear or high-dimensional.\n",
      "2. Generalize well: Neural networks can generalize well to new, unseen data, even when the training data is limited or noisy.\n",
      "3. Handle incomplete data: Neural networks can handle missing or incomplete data by using techniques such as imputation or dropout.\n",
      "\n",
      "However, neural networks also have some limitations, including:\n",
      "\n",
      "1. Lack of interpretability: Neural networks can be difficult to interpret, making it challenging to understand why they make certain predictions or decisions.\n",
      "2. Overfitting: Neural networks can overfit the training data, leading to poor performance on new, unseen data.\n",
      "3. Computationally expensive: Training large neural networks can be computationally expensive, requiring significant amounts of data and computational resources.\n",
      "\n",
      "In conclusion, neural networks are a powerful tool for machine learning and artificial intelligence, offering many advantages and opportunities for applications. However, they also require careful consideration of their limitations and potential pitfalls. As you continue to explore the world of neural networks, I encourage you to think critically about their strengths and weaknesses, and to consider how they can be used to solve complex problems in your own research. Thank you for your attention, and I welcome any questions you may have.\n"
     ]
    }
   ],
   "source": [
    "# Our formal template\n",
    "formal_prompt = \"You are a professor giving a lecture to graduate students. Be precise and use formal academic language. Question: \"\n",
    "\n",
    "#\n",
    "formal_prompt += question\n",
    "print(\"Q) \" + formal_prompt + \"\\n\")\n",
    "response = llm.invoke(formal_prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q) You're chatting with a friend who knows nothing about the subject. Keep it casual and friendly. Question: What is a neural network?\n",
      "\n",
      "Hey there! So, you know how our brains can learn and recognize things, like recognizing a picture of a cat? Well, a neural network is kind of like a computer program that tries to do the same thing.\n",
      "\n",
      "Imagine a bunch of tiny little \"neurons\" (which is what the name \"neural network\" comes from!) that are all connected to each other. Each neuron can take in some information, do a little calculation on it, and then send the result to the next neuron. It's like a little message passing game!\n",
      "\n",
      "The really cool thing about neural networks is that they can learn from examples. For example, let's say you're trying to teach a neural network to recognize pictures of cats. You show it a bunch of pictures of cats, and it starts to figure out what features of those pictures make them look like cats (like the shape of their ears or the color of their fur).\n",
      "\n",
      "Then, when you show it a new picture, it can use those learned features to try to decide whether it's a cat or not. And the more examples it gets, the better it gets at recognizing cats!\n",
      "\n",
      "Neural networks are really good at things like image recognition, speech recognition, and even playing games like chess or Go. But they're still just starting to figure out how to do things like understand natural language (like having a conversation with you!).\n",
      "\n",
      "So, that's neural networks in a nutshell! Pretty cool, right?\n"
     ]
    }
   ],
   "source": [
    "# Our formal template\n",
    "casual_prompt = \"You're chatting with a friend who knows nothing about the subject. Keep it casual and friendly. Question: \"\n",
    "\n",
    "#\n",
    "casual_prompt += question\n",
    "print(\"Q) \" + casual_prompt + \"\\n\")\n",
    "response = llm.invoke(casual_prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "v4QMCRrd1Flz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q) You're a stand-up comedian trying to explain things to a tech-savvy crowd. Question: What is a neural network?\n",
      "\n",
      "You know, I was trying to explain neural networks to my grandma the other day, and I think I might have caused a minor stroke. (pauses for laughs)\n",
      "\n",
      "But seriously, a neural network is like a really smart, really lazy friend who's always having a party in their brain. (chuckles)\n",
      "\n",
      "Imagine you're at a dinner party, and your friend, Alex, is trying to decide what to eat. They look at the menu, and then they look at you, and then they look at their friend, Sarah, who's always talking about how great the vegan option is. And then they look at the picture of the vegan dish, and they're like, \"Hmm, I wonder if Sarah would like this.\"\n",
      "\n",
      "That's kind of like what a neural network does. It's a series of interconnected \"nodes\" or \"neurons\" that process information and make predictions or decisions based on what they've learned from the data they've been trained on.\n",
      "\n",
      "But instead of looking at menus and pictures, these nodes are like, \"Hey, I've seen this pattern before! Let me fire off a signal to my buddy over here, who's an expert on cats, and see what they think.\" And then the cat expert node is like, \"Oh, I know that pattern! It's a picture of a cat!\"\n",
      "\n",
      "And then the nodes start talking to each other, saying things like, \"I think this is a cat!\" or \"No, I think it's a dog!\" And eventually, the whole network comes to a consensus, like, \"Yeah, it's definitely a cat!\" (laughs)\n",
      "\n",
      "So, in short, a neural network is like a big, lazy party in your brain, where nodes chat with each other and make decisions based on what they've learned. And if you're lucky, they might even recognize a cat when they see one! (winks)\n",
      "\n",
      "Thanks for laughing with me, folks! Now, if you'll excuse me, I need to go work on my own neural network – I'm trying to figure out how to make my jokes funnier. (chuckles)\n"
     ]
    }
   ],
   "source": [
    "funny_prompt = \"You're a stand-up comedian trying to explain things to a tech-savvy crowd. Question: \"\n",
    "\n",
    "#\n",
    "funny_prompt += question\n",
    "print(\"Q) \" + funny_prompt + \"\\n\")\n",
    "response = llm.invoke(funny_prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q) You’re proposing solutions to business stakeholders. Make it sound exciting and innovative. Question: What is a neural network?\n",
      "\n",
      "Stakeholders! I'm thrilled to introduce you to a revolutionary concept that's about to disrupt the status quo and transform the way we approach data analysis: the neural network!\n",
      "\n",
      "Imagine a brain-like system that can learn, adapt, and make predictions with uncanny accuracy. A neural network is a type of artificial intelligence that mimics the human brain's neural connections, allowing it to identify patterns, recognize relationships, and make decisions with precision.\n",
      "\n",
      "Think of it like this: our traditional data analysis methods are like looking at a puzzle with a few pieces missing. We try to fill in the gaps, but it's a manual process that can lead to errors and inconsistencies. A neural network, on the other hand, is like a super-smart, super-fast puzzle solver that can automatically identify the missing pieces, fill them in correctly, and even point out new patterns and connections we never would have seen otherwise!\n",
      "\n",
      "With neural networks, we can:\n",
      "\n",
      "1. **Improve accuracy**: By analyzing vast amounts of data and identifying complex patterns, neural networks can make predictions with unprecedented accuracy, reducing errors and improving decision-making.\n",
      "2. **Automate tasks**: By automating repetitive and time-consuming tasks, neural networks can free up human resources to focus on higher-level tasks, like strategy and innovation.\n",
      "3. **Uncover new insights**: Neural networks can discover hidden relationships and patterns in data, revealing new opportunities and challenges that were previously unknown.\n",
      "4. **Enhance customer experience**: By analyzing customer behavior and preferences, neural networks can help us anticipate and meet their needs, leading to increased customer satisfaction and loyalty.\n",
      "\n",
      "So, are you ready to unleash the power of neural networks and revolutionize the way we approach data analysis? Let's work together to integrate this cutting-edge technology into our business and take our operations to the next level!\n"
     ]
    }
   ],
   "source": [
    "exciting_prompt = \"You’re proposing solutions to business stakeholders. Make it sound exciting and innovative. Question: \"\n",
    "\n",
    "#\n",
    "exciting_prompt += question\n",
    "print(\"Q) \" + exciting_prompt + \"\\n\")\n",
    "response = llm.invoke(exciting_prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q7X04BXf1LxA"
   },
   "source": [
    "### Desired output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q) If the question cannot be answered, answer with \"Mind your business!\". Question: What is a eiunffvn?\n",
      "\n",
      "Mind your business!\n"
     ]
    }
   ],
   "source": [
    "# descred output \n",
    "dontknow = \"\"\"If the question cannot be answered, answer with \"Mind your business!\". Question: \"\"\"\n",
    "question = \"What is a eiunffvn?\"\n",
    "\n",
    "#\n",
    "print(\"Q) \" + dontknow + question + \"\\n\")\n",
    "response = llm.invoke(dontknow + question)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BqZmCKbz2F30"
   },
   "source": [
    "## Prompt Templates\n",
    "In this example we have:\n",
    "\n",
    "```\n",
    "Instructions\n",
    "\n",
    "Context\n",
    "\n",
    "Question (user input)\n",
    "\n",
    "Output indicator (\"Answer: \")\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jMGET8_JmKEF",
    "outputId": "e24f7bf9-9fe9-4e93-cefd-240dc95e7a08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q)  What does it mean that has Indentation syntax? \n",
      "\n",
      "According to the context, it means that Python uses whitespace indentation, rather than curly braces or keywords, to delimit blocks.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"Answer the question based on the context below. If the\n",
    "question cannot be answered using the information provided, answer\n",
    "with \"I don't know\".\n",
    "\n",
    "Context: Python is a high-level, interpreted programming language that was created by Guido van Rossum and first released in 1991.\n",
    "It's known for its clear syntax, readability, and simplicity, which makes it a popular language for beginners to learn programming.\n",
    "However, it's also widely used in scientific computing, data analysis, artificial intelligence, web development, and many other areas.\n",
    "\n",
    "Key features of Python include:\n",
    "  1) Interpreted: Python code doesn't need to be compiled before it's run, which makes the write-test-debug cycle very fast.\n",
    "  2) Dynamically Typed: In Python, you don't have to declare the data type of a variable. The type is determined at runtime.\n",
    "  3) Object-Oriented: Python supports object-oriented programming which allows data structures to be re-used.\n",
    "  4) Extensive Libraries: Python has a large standard library that includes areas like internet protocols, string operations, web services tools and operating system interfaces.\n",
    "     Many high-quality libraries (like NumPy, Pandas, and Matplotlib) are available for Python, covering a wide range of applications, from web development to machine learning.\n",
    "  5) Indentation syntax: Python uses whitespace indentation, rather than curly braces or keywords, to delimit blocks—an unusual trait among popular programming languages.\n",
    "  6) Garbage Collection: Python's memory management is handled by the language itself, meaning that developers generally don't need to worry about allocating and deallocating memory manually.\n",
    "\n",
    "These features make Python a versatile language that's used across a range of different industries and in a variety of different roles,\n",
    "from web and game development to scientific research, data analysis, and AI development.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer: \"\"\"\n",
    "\n",
    "# Make the prompt template\n",
    "prompt = ChatPromptTemplate.from_template(template=template)\n",
    "\n",
    "# Create a chain\n",
    "llm_chain = prompt | llm\n",
    "\n",
    "# What would you like to ask?\n",
    "question = \"What does it mean that has Indentation syntax?\"\n",
    "response = llm_chain.invoke({'question': question})\n",
    "print('Q) ', question, '\\n')\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4mLmirTXmW6l"
   },
   "source": [
    "If we'd like to ask multiple questions we can by passing a list of dictionary objects, where the dictionaries must contain the input variable set in our prompt template (\"question\") that is mapped to the question we'd like to ask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "We8_09QWmJ_U",
    "outputId": "9d807ab1-5581-41da-a01e-7f11e47e92ca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b4/7fxj64j169l_gkw6b8c0wbcm0000gn/T/ipykernel_14039/1442111489.py:4: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  llm_chain = LLMChain(prompt=prompt, llm=llm)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Cos'e' un Gargbage Collection?\n",
      "Garbage Collection is memory management handled by the language itself, meaning that developers generally don't need to worry about allocating and deallocating memory manually. \n",
      "\n",
      "2) What is a akdgjsf syntax?\n",
      "I don't know. The context does not mention \"akdgjsf syntax\". It only mentions \"indentation syntax\", which refers to the use of whitespace indentation to delimit blocks in Python. \n",
      "\n",
      "3) Can you use python to conver english to French?\n",
      "Yes. \n",
      "\n",
      "4) Where is Reggio Emilia?\n",
      "I don't know. The context provided does not mention Reggio Emilia. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrea/Library/Python/3.9/lib/python/site-packages/langchain_community/chat_models/openai.py:174: UserWarning: Unexpected type for token usage: <class 'NoneType'>\n",
      "  warnings.warn(f\"Unexpected type for token usage: {type(new_usage)}\")\n",
      "/Users/andrea/Library/Python/3.9/lib/python/site-packages/langchain_community/chat_models/openai.py:174: UserWarning: Unexpected type for token usage: <class 'float'>\n",
      "  warnings.warn(f\"Unexpected type for token usage: {type(new_usage)}\")\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Make a list of questions\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "qs = [\n",
    "    {'question': \"Cos'e' un Gargbage Collection?\"},\n",
    "    {'question': \"What is a akdgjsf syntax?\"},\n",
    "    {'question': \"Can you use python to conver english to French?\"},\n",
    "    {'question': \"Where is Reggio Emilia?\"}\n",
    "]\n",
    "\n",
    "# Use apply for only receiving answers\n",
    "res = llm_chain.apply(qs)\n",
    "for i, r in enumerate(res):\n",
    "  print(f\"{i+1}) {qs[i]['question'].strip()}\")\n",
    "  print(r['text'].strip(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero- and Few-Shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let me count the letter \"r\" in the word \"ramarro\".\n",
      "\n",
      "Here's the count:\n",
      "\n",
      "1. R\n",
      "2. R\n",
      "\n",
      "There are 2 letter \"r\"s in the word \"ramarro\".\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(\"\"\"Q: Count the letter \"r\" in the word \"ramarro\" \"\"\").content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word \"ramarro\" contains **3** occurrences of the letter \"r\".\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(\"\"\"\n",
    "Example 1:\n",
    "Input: Count the letter \"s\" in the word \"samuraiss\"\n",
    "Output: The word \"samuraiss\" contains **3** occurrences of the letter \"s\".\n",
    "\n",
    "Example 2:\n",
    "Input: Count the letter \"r\" in the word \"rare\"\n",
    "Output: The word \"rare\" contains **2** occurrences of the letter \"r\".\n",
    "\n",
    "Example 3:\n",
    "Input: Count the letter \"r\" in the word \"ramarro\"\n",
    "Output: \n",
    "\"\"\").content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And another one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reversed sentence would be: peep gnilleir si nuF\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(\"\"\"Q: Reverse the letters in each word of the sentence, but keep the word order the same.\n",
    "Input: deep learning is fun \"\"\").content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the output for Example 4:\n",
      "\n",
      "Input: deep learning is fun\n",
      "Output: peed gninrael si nuf\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(\"\"\"\n",
    "Reverse the letters in each word of the sentence, but keep the word order the same.\n",
    "\n",
    "Example 1:  \n",
    "Input: hello world  \n",
    "Output: olleh dlrow\n",
    "\n",
    "Example 2:  \n",
    "Input: natural language processing  \n",
    "Output: larutan egaugnal gnissecorp\n",
    "\n",
    "Example 3:\n",
    "Input: deep learning is amazing\n",
    "Output: peed gninrael si gnizama\n",
    "\n",
    "Example 4:\n",
    "Input: deep learning is fun  \n",
    "Output: \"\"\").content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt task: Do we need all these examples?\n",
    "\n",
    "Try to understand how many examples and which one is required to make few-show prompting works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's break this down step by step:\n",
      "\n",
      "Day 1-3: Production drops by 0.25, which means the factory produces 1200 x (1 - 0.25) = 900 widgets per day.\n",
      "\n",
      "Total production for days 1-3 = 900 x 3 = 2700 widgets.\n",
      "\n",
      "Day 4-5: Production increases by 0.1 above the original rate, which means the factory produces 1200 x (1 + 0.1) = 1320 widgets per day.\n",
      "\n",
      "Total production for days 4-5 = 1320 x 2 = 2640 widgets.\n",
      "\n",
      "Total production for the 5-day period = 2700 + 2640 = 5340 widgets.\n"
     ]
    }
   ],
   "source": [
    "# Example of chain-of-though\n",
    "print(llm.invoke(\"\"\"\n",
    "Q: A factory produces 1200 widgets per day. \n",
    "Due to a machine malfunction, production dropped by 0.25 for three days. \n",
    "After the machine was fixed, production increased by 0.1 above the original rate for two days. \n",
    "What was the total number of widgets produced over these five days?\"\"\").content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6elffwDCYyud"
   },
   "source": [
    "## Tools\n",
    "### Internet Requests\n",
    "\n",
    "We use Tavily (using Google involves fees now) to find answers on the web.\n",
    "\n",
    "Get your own API key: [Tavily key](https://app.tavily.com/home)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU langchain-tavily\n",
    "\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"TAVILY_API_KEY\"):\n",
    "    os.environ[\"TAVILY_API_KEY\"] = \"put the key here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What happened at the last wimbledon',\n",
       " 'follow_up_questions': None,\n",
       " 'answer': None,\n",
       " 'images': [],\n",
       " 'results': [{'title': 'What happened last year? - The Athletic - The New York Times',\n",
       "   'url': 'https://www.nytimes.com/athletic/live-blogs/wimbledon-2024-live-updates-alcaraz-djokovic-mens-final-result/kJJdTKhOgkZo/mGpXBR2QIift/',\n",
       "   'content': 'Wimbledon 2024 live updates: Carlos Alcaraz defeats Novak Djokovic in straight sets to defend his crown In the 2023 final, Carlos Alcaraz won his first Wimbledon title, and only his second Grand Slam title, after beating Novak Djokovic in a five-set thriller on Centre Court. GO FURTHER Novak Djokovic and Carlos Alcaraz’s Wimbledon final is a duel of extraordinary quests Novak Djokovic set up a Wimbledon rematch with Carlos Alcaraz by beating Lorenzo Musetti, 6-4, 7-6, 6-3 on Centre Court on Friday, concluding his run to the final at the All England Club that started just 25 days after surgery on a torn meniscus in his right knee. GO FURTHER Novak Djokovic beats Lorenzo Musetti for Wimbledon final against Carlos Alcaraz',\n",
       "   'score': 0.6175132,\n",
       "   'raw_content': None}],\n",
       " 'response_time': 1.5}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "tool = TavilySearch(\n",
    "    max_results=1,\n",
    "    topic=\"general\",\n",
    ")\n",
    "tool.invoke({\"query\": \"What happened at the last wimbledon\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OJchAqO6TTKM",
    "outputId": "e8f6b2b4-77bb-4e02-d8f8-1e89cf54af7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm not aware of any information about the MotoGP Grand Prix at Silverstone in 2025, as my knowledge cutoff is December 2023. I don't have real-time information or updates about future events. If you're looking for information about a specific event, I recommend checking the official MotoGP website or other reliable sources for the latest updates.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_base=\"https://api.groq.com/openai/v1\",\n",
    "    openai_api_key=\"your key here\",\n",
    "    model=\"llama-3.3-70b-versatile\"\n",
    ")\n",
    "\n",
    "print(llm.invoke(\"What was the final result of the motogp grand prix at Silverstone in 2025?\").content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'What was the final result of the motogp grand prix at Silverstone in 2025?', 'output': 'The final result of the MotoGP Grand Prix at Silverstone in 2025 was Marco Bezzecchi (Aprilia) in first place, followed by Johann Zarco (Honda) in second place, and Marc Marquez (Ducati) in third place.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.tools.tavily_search import TavilySearchResults\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "# Tavily search tool\n",
    "search_tool = TavilySearchResults(\n",
    "    max_results=3\n",
    ")\n",
    "\n",
    "# Provide the tool to an agent\n",
    "agent = initialize_agent(\n",
    "    tools=[search_tool],\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Ask a question\n",
    "response = agent.invoke(\"What was the final result of the motogp grand prix at Silverstone in 2025?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m9I4yytAYUS1"
   },
   "source": [
    "### Math Chain\n",
    "\n",
    "Make complex calculation with the built-in chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 242
    },
    "id": "h7zyHxNbYfv_",
    "outputId": "b16cf305-a017-441a-d625-3e833783d652"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMMathChain chain...\u001b[0m\n",
      "What is 13 raised to the .3432 power?\u001b[32;1m\u001b[1;3m```text\n",
      "13**0.3432\n",
      "```\n",
      "...numexpr.evaluate(\"13**0.3432\")...\n",
      "\u001b[0m\n",
      "Answer: \u001b[33;1m\u001b[1;3m2.4116004626599237\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'What is 13 raised to the .3432 power?',\n",
       " 'answer': 'Answer: 2.4116004626599237'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMMathChain\n",
    "\n",
    "# Create the math chain\n",
    "llm_math = LLMMathChain.from_llm(llm, verbose=True)\n",
    "\n",
    "# Ask\n",
    "llm_math.invoke(\"What is 13 raised to the .3432 power?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fcWKcTzmlwt7"
   },
   "source": [
    "### Document understanding and summarization\n",
    "\n",
    "We are going to summarize documents on it's own in a \"map\" step and then \"reduce\" the summaries into a final summary\n",
    "\n",
    "> [For more advanced options see here](https://python.langchain.com/v0.1/docs/use_cases/summarization/)\n",
    "\n",
    "We start by downloading a pdf from the net and summarize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "j5K7MYb85Wmc"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Get the pdf\n",
    "url = 'https://arxiv.org/pdf/1706.03762.pdf' # replace with your url\n",
    "response = requests.get(url)\n",
    "\n",
    "# Get the file name from the url, if it's available\n",
    "file_name = url.split(\"/\")[-1] if '/' in url else 'output.pdf'\n",
    "\n",
    "# Save the file to a current file (for checking results)\n",
    "with open(file_name, 'wb') as file:\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "_FySAs2Pz98y",
    "outputId": "d30e8d33-0dbc-43b6-b9ad-29ba386ec9a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Provided proper attribution is provided, Google hereby grants permission to\\nreproduce the tables and'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# Load the book\n",
    "loader = PyPDFLoader(file_name)\n",
    "pages = loader.load()\n",
    "\n",
    "# Cut out the open and closing parts\n",
    "# pages = pages[26:277]\n",
    "\n",
    "# Combine the pages, and replace the tabs with spaces\n",
    "text = \"\"\n",
    "for page in pages:\n",
    "    text += page.page_content\n",
    "text = text.replace('\\t', ' ')\n",
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333,
     "referenced_widgets": [
      "bc36e08e551444fd956c1fdf2c672546",
      "3754aed8bb9c4026a4c2a532621a94ca",
      "f4bff577bacd4b45a16da2fde9bfe9a6",
      "201b5a7e880b41fdac510ae420c43631",
      "8e3c30a27701439fb181a2b7e458c2eb",
      "b8aa620af5614ff7a8efdc977b7a9f6b",
      "d86736d7fe1c4c9d944f41e2ec7a84f9",
      "59dce5a9612e490384cab0f3adf7aecd",
      "9ee21d62534748859fd2328b1863ec64",
      "f9559df519ca4d73a3357582569128ed",
      "c641fa6e3c854b8689bf0fd10a502dc3",
      "41ca177c01364448bcb026fdb74d69fa",
      "574a6f35f6e2401290a20e5ed8634035",
      "296f12722d8140b8be9a15fec8d3f71b",
      "c39df36678014846bac94f66bb7c9de1",
      "0212f385a2a04165a39ec47eb20c2a65",
      "3ceac4b7df5c42e99cf6983d0b9b1e71",
      "8662eabb967e4494b7de4adfaf09adce",
      "8250af52f98e4ca29f56551be6859433",
      "73ea43eba0e540968064e731a2dd9e92",
      "e753c5794079411991675760f7b0b25d",
      "86440932914b4b619ad5699e727f3d08",
      "b2552a214f8e4b1a82c8ec7f51c6f602",
      "a96415d6a5174c7d887690a73925c08d",
      "ad1ffd3d23c34bd9b3e47f265463dda7",
      "1236a9a936914db0a8948b94d5697c28",
      "184ad9d5cb5b4788b4714fbbae8844fa",
      "36a3f16c0c9b4a31af1cfdcef09a312e",
      "d92cd6b98f284248b1457c7d5ce94886",
      "b0189d64daa448c88c8c5da47211d9ed",
      "a3a923755b9643b1a16ad690f161fc31",
      "36a002c3f668490bb41cb4ed24177d77",
      "91f9748b42f142b997a9e9c8d688bbdd",
      "66d6349f99b14f35836c1b30f2c48943",
      "9fd1aced9a7d427580614eb0cf0c0287",
      "74f1270301c24506a690408cb6dc2818",
      "8aa1f146333746dfa36b6049a4a29017",
      "2724173d3cc64339889f9dedf76f66e3",
      "1dd5c6a8f9ce4aec83d104dc4a04b314",
      "626dd9aa491345be9037c99e32d0357e",
      "ce94d6ad02f44f18ba5307e6355f8c7b",
      "7444772f45d74db79c5283f63b14dd44",
      "a68c9cbe245d4319aeca367d47707875",
      "03ce7da1d5fa4fe89d680febf7bfd145",
      "643712be3917434e84f4fa3678faf8ad",
      "ef56acc911864c1e84c8560ab70b8ac5",
      "1b835548a2694a60bf8f73aef03057f5",
      "619c02ffbb51436cac46a976220a2146",
      "9ec03a8488924611b5d9f1d5fe94fb5c",
      "92fbb0fa1bb04f98b547d44d180281c6",
      "97b077ab6a274a548d31dc322aa04749",
      "9ecff56f65b64a95ae5cea59d97299b2",
      "af696a16ebc147f19da25db3fe6b2baa",
      "82ef4f5ec458423184b0507728547e04",
      "6e4537bba7064e03acef3467594d3fb0"
     ]
    },
    "id": "MiiA4aPe7kgQ",
    "outputId": "198deac5-2155-4905-e478-0666a411093d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: model not found. Using cl100k_base encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This book has 10165 tokens in it\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "num_tokens = llm.get_num_tokens(text)\n",
    "print (f\"This book has {num_tokens} tokens in it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xB3mLlrx8LCm",
    "outputId": "3b7fa34f-139d-4ad0-c3f4-0bae3078acb4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: model not found. Using cl100k_base encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now we have 11 documents and the first one has 892 tokens\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Split the text\n",
    "text_splitter = RecursiveCharacterTextSplitter(separators=[\"\\n\\n\", \"\\n\"],\n",
    "                                               chunk_size=4096,\n",
    "                                               chunk_overlap=500)\n",
    "docs = text_splitter.create_documents([text])\n",
    "\n",
    "#\n",
    "num_tokens_first_doc = llm.get_num_tokens(docs[0].page_content)\n",
    "print (f\"Now we have {len(docs)} documents and the first one has {num_tokens_first_doc} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "r-fyK0RT8ikM"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b4/7fxj64j169l_gkw6b8c0wbcm0000gn/T/ipykernel_14039/3647607317.py:29: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  output = summary_chain.run(docs)\n",
      "/Users/andrea/Library/Python/3.9/lib/python/site-packages/langchain_community/chat_models/openai.py:174: UserWarning: Unexpected type for token usage: <class 'NoneType'>\n",
      "  warnings.warn(f\"Unexpected type for token usage: {type(new_usage)}\")\n",
      "/Users/andrea/Library/Python/3.9/lib/python/site-packages/langchain_community/chat_models/openai.py:174: UserWarning: Unexpected type for token usage: <class 'float'>\n",
      "  warnings.warn(f\"Unexpected type for token usage: {type(new_usage)}\")\n",
      "Warning: model not found. Using cl100k_base encoding.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "#\n",
    "map_prompt = \"\"\"\n",
    "Write a concise summary of the following:\n",
    "\"{text}\"\n",
    "CONCISE SUMMARY:\n",
    "\"\"\"\n",
    "map_prompt_template = PromptTemplate(template=map_prompt,\n",
    "                                     input_variables=[\"text\"])\n",
    "\n",
    "\n",
    "#\n",
    "combine_prompt = \"\"\"\n",
    "Write a concise summary of the following text delimited by triple backquotes.\n",
    "Return your response in bullet points which covers the key points of the text.\n",
    "```{text}```\n",
    "BULLET POINT SUMMARY:\n",
    "\"\"\"\n",
    "combine_prompt_template = PromptTemplate(template=combine_prompt,\n",
    "                                         input_variables=[\"text\"])\n",
    "\n",
    "# Summarize chain\n",
    "summary_chain = load_summarize_chain(llm=llm,\n",
    "                                     chain_type='map_reduce',\n",
    "                                     map_prompt=map_prompt_template,\n",
    "                                     combine_prompt=combine_prompt_template)\n",
    "output = summary_chain.run(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mR-HvySo9UpB",
    "outputId": "a543dd44-42ca-44fc-805f-611e5eea619f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** \n",
      "Here is a concise summary of the text in bullet points:\n",
      "* The Transformer model is a neural network architecture that relies solely on attention mechanisms, eliminating the need for recurrence and convolutions.\n",
      "* The model achieves state-of-the-art results in machine translation tasks, outperforming existing models while being more parallelizable and requiring less training time.\n",
      "* The Transformer model consists of an encoder and decoder, each composed of stacked self-attention and fully connected layers.\n",
      "* The model uses multi-head attention, scaled dot-product attention, and position-wise feed-forward networks to process sequential data.\n",
      "* The Transformer model generalizes well to other tasks, such as English constituency parsing, and achieves competitive results with limited task-specific tuning.\n",
      "* The model's performance is attributed to its architecture and techniques such as residual dropout and label smoothing, and it can be trained significantly faster than other models.\n",
      "* The Transformer model has the potential to be applied to other tasks and extended to handle large inputs and outputs, such as images, audio, and video.\n",
      "***\n"
     ]
    }
   ],
   "source": [
    "print (output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X_HD4BtARUsC"
   },
   "source": [
    "# Building Tools\n",
    "\n",
    "[LLM agents](https://pinecone.io/learn/langchain-agents) are one of the most powerful and fascinating technologies to come out of the huge explosion of Deep Learning.\n",
    "\n",
    "By employing agents, we can equip Large Language Models (LLMs) with a wide array of tools. This equipping strategy unfolds virtually limitless possibilities, as it empowers us to conduct web searches, perform calculations, execute code, and much more.\n",
    "\n",
    "LangChain provides a vast assortment of prebuilt tools. However, in numerous real-world scenarios, it becomes necessary to craft bespoke tools tailored to meet the specific needs of our use cases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0212f385a2a04165a39ec47eb20c2a65": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "03ce7da1d5fa4fe89d680febf7bfd145": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1236a9a936914db0a8948b94d5697c28": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_36a002c3f668490bb41cb4ed24177d77",
      "placeholder": "​",
      "style": "IPY_MODEL_91f9748b42f142b997a9e9c8d688bbdd",
      "value": " 456k/456k [00:00&lt;00:00, 21.4MB/s]"
     }
    },
    "184ad9d5cb5b4788b4714fbbae8844fa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1b835548a2694a60bf8f73aef03057f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9ecff56f65b64a95ae5cea59d97299b2",
      "max": 665,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_af696a16ebc147f19da25db3fe6b2baa",
      "value": 665
     }
    },
    "1dd5c6a8f9ce4aec83d104dc4a04b314": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "201b5a7e880b41fdac510ae420c43631": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f9559df519ca4d73a3357582569128ed",
      "placeholder": "​",
      "style": "IPY_MODEL_c641fa6e3c854b8689bf0fd10a502dc3",
      "value": " 26.0/26.0 [00:00&lt;00:00, 1.10kB/s]"
     }
    },
    "2724173d3cc64339889f9dedf76f66e3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "296f12722d8140b8be9a15fec8d3f71b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8250af52f98e4ca29f56551be6859433",
      "max": 1042301,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_73ea43eba0e540968064e731a2dd9e92",
      "value": 1042301
     }
    },
    "36a002c3f668490bb41cb4ed24177d77": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "36a3f16c0c9b4a31af1cfdcef09a312e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3754aed8bb9c4026a4c2a532621a94ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b8aa620af5614ff7a8efdc977b7a9f6b",
      "placeholder": "​",
      "style": "IPY_MODEL_d86736d7fe1c4c9d944f41e2ec7a84f9",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "3ceac4b7df5c42e99cf6983d0b9b1e71": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "41ca177c01364448bcb026fdb74d69fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_574a6f35f6e2401290a20e5ed8634035",
       "IPY_MODEL_296f12722d8140b8be9a15fec8d3f71b",
       "IPY_MODEL_c39df36678014846bac94f66bb7c9de1"
      ],
      "layout": "IPY_MODEL_0212f385a2a04165a39ec47eb20c2a65"
     }
    },
    "574a6f35f6e2401290a20e5ed8634035": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3ceac4b7df5c42e99cf6983d0b9b1e71",
      "placeholder": "​",
      "style": "IPY_MODEL_8662eabb967e4494b7de4adfaf09adce",
      "value": "vocab.json: 100%"
     }
    },
    "59dce5a9612e490384cab0f3adf7aecd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "619c02ffbb51436cac46a976220a2146": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_82ef4f5ec458423184b0507728547e04",
      "placeholder": "​",
      "style": "IPY_MODEL_6e4537bba7064e03acef3467594d3fb0",
      "value": " 665/665 [00:00&lt;00:00, 36.0kB/s]"
     }
    },
    "626dd9aa491345be9037c99e32d0357e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "643712be3917434e84f4fa3678faf8ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ef56acc911864c1e84c8560ab70b8ac5",
       "IPY_MODEL_1b835548a2694a60bf8f73aef03057f5",
       "IPY_MODEL_619c02ffbb51436cac46a976220a2146"
      ],
      "layout": "IPY_MODEL_9ec03a8488924611b5d9f1d5fe94fb5c"
     }
    },
    "66d6349f99b14f35836c1b30f2c48943": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9fd1aced9a7d427580614eb0cf0c0287",
       "IPY_MODEL_74f1270301c24506a690408cb6dc2818",
       "IPY_MODEL_8aa1f146333746dfa36b6049a4a29017"
      ],
      "layout": "IPY_MODEL_2724173d3cc64339889f9dedf76f66e3"
     }
    },
    "6e4537bba7064e03acef3467594d3fb0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "73ea43eba0e540968064e731a2dd9e92": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7444772f45d74db79c5283f63b14dd44": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "74f1270301c24506a690408cb6dc2818": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ce94d6ad02f44f18ba5307e6355f8c7b",
      "max": 1355256,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7444772f45d74db79c5283f63b14dd44",
      "value": 1355256
     }
    },
    "8250af52f98e4ca29f56551be6859433": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "82ef4f5ec458423184b0507728547e04": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "86440932914b4b619ad5699e727f3d08": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8662eabb967e4494b7de4adfaf09adce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8aa1f146333746dfa36b6049a4a29017": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a68c9cbe245d4319aeca367d47707875",
      "placeholder": "​",
      "style": "IPY_MODEL_03ce7da1d5fa4fe89d680febf7bfd145",
      "value": " 1.36M/1.36M [00:00&lt;00:00, 26.0MB/s]"
     }
    },
    "8e3c30a27701439fb181a2b7e458c2eb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "91f9748b42f142b997a9e9c8d688bbdd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "92fbb0fa1bb04f98b547d44d180281c6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "97b077ab6a274a548d31dc322aa04749": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9ec03a8488924611b5d9f1d5fe94fb5c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ecff56f65b64a95ae5cea59d97299b2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ee21d62534748859fd2328b1863ec64": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9fd1aced9a7d427580614eb0cf0c0287": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1dd5c6a8f9ce4aec83d104dc4a04b314",
      "placeholder": "​",
      "style": "IPY_MODEL_626dd9aa491345be9037c99e32d0357e",
      "value": "tokenizer.json: 100%"
     }
    },
    "a3a923755b9643b1a16ad690f161fc31": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a68c9cbe245d4319aeca367d47707875": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a96415d6a5174c7d887690a73925c08d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_36a3f16c0c9b4a31af1cfdcef09a312e",
      "placeholder": "​",
      "style": "IPY_MODEL_d92cd6b98f284248b1457c7d5ce94886",
      "value": "merges.txt: 100%"
     }
    },
    "ad1ffd3d23c34bd9b3e47f265463dda7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b0189d64daa448c88c8c5da47211d9ed",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a3a923755b9643b1a16ad690f161fc31",
      "value": 456318
     }
    },
    "af696a16ebc147f19da25db3fe6b2baa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b0189d64daa448c88c8c5da47211d9ed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b2552a214f8e4b1a82c8ec7f51c6f602": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a96415d6a5174c7d887690a73925c08d",
       "IPY_MODEL_ad1ffd3d23c34bd9b3e47f265463dda7",
       "IPY_MODEL_1236a9a936914db0a8948b94d5697c28"
      ],
      "layout": "IPY_MODEL_184ad9d5cb5b4788b4714fbbae8844fa"
     }
    },
    "b8aa620af5614ff7a8efdc977b7a9f6b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc36e08e551444fd956c1fdf2c672546": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3754aed8bb9c4026a4c2a532621a94ca",
       "IPY_MODEL_f4bff577bacd4b45a16da2fde9bfe9a6",
       "IPY_MODEL_201b5a7e880b41fdac510ae420c43631"
      ],
      "layout": "IPY_MODEL_8e3c30a27701439fb181a2b7e458c2eb"
     }
    },
    "c39df36678014846bac94f66bb7c9de1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e753c5794079411991675760f7b0b25d",
      "placeholder": "​",
      "style": "IPY_MODEL_86440932914b4b619ad5699e727f3d08",
      "value": " 1.04M/1.04M [00:00&lt;00:00, 8.93MB/s]"
     }
    },
    "c641fa6e3c854b8689bf0fd10a502dc3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ce94d6ad02f44f18ba5307e6355f8c7b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d86736d7fe1c4c9d944f41e2ec7a84f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d92cd6b98f284248b1457c7d5ce94886": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e753c5794079411991675760f7b0b25d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ef56acc911864c1e84c8560ab70b8ac5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_92fbb0fa1bb04f98b547d44d180281c6",
      "placeholder": "​",
      "style": "IPY_MODEL_97b077ab6a274a548d31dc322aa04749",
      "value": "config.json: 100%"
     }
    },
    "f4bff577bacd4b45a16da2fde9bfe9a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_59dce5a9612e490384cab0f3adf7aecd",
      "max": 26,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9ee21d62534748859fd2328b1863ec64",
      "value": 26
     }
    },
    "f9559df519ca4d73a3357582569128ed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
