{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlbz3_5-mllE"
   },
   "source": [
    "# Unlocking the Potential of Large Language Models with LangChain\n",
    "\n",
    "\n",
    "[LangChain](https://python.langchain.com/en/latest/getting_started/getting_started.html) is a widely used framework that enables users to easily develop applications and pipelines using Large Language Models (LLMs). With LangChain, you can create chatbots, Generative Question-Answering (GQA) systems, summarization tools, and much more.\n",
    "\n",
    "At the core of LangChain's design is the idea of \"chaining\" together different components to create more sophisticated LLM use-cases. These chains can comprise multiple components from various modules, including:\n",
    "\n",
    "  * ***Prompt Templates***: serve as pre-defined structures for different types of prompts such as chatbot-style interactions and more.\n",
    "\n",
    "  * ***Large Language Models***: LLMs such as GPT-3, BLOOM and Jurassic are used in LangChain to generate responses or perform language-related tasks.\n",
    "\n",
    "  * ***Agents***: utilize LLMs to determine the appropriate actions to take, using tools such as web search or calculators to execute operations within a logical loop.\n",
    "\n",
    "  * ***Memory***: LangChain provides both short-term and long-term memory to help LLMs retain information and improve their responses over time.\n",
    "\n",
    "With these modules, LangChain offers a comprehensive solution for developing advanced LLM-based applications that can enhance natural language processing in various fields.\n",
    "\n",
    "The following code downloads the necessary python libraries needed in this LAB, and then it load them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9g12MudNgIVd",
    "outputId": "81dc853f-b43e-45e4-a61a-34b5e9e6271a"
   },
   "outputs": [],
   "source": [
    "!pip install langchain==0.3.25\n",
    "!pip install langchain_community==0.3.24\n",
    "!pip install langchain_ai21\n",
    "!pip install pypdf, tiktoken, numexpr, transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQHXSQ54mKen"
   },
   "source": [
    "Afterwards, the API to the Large Language Models provided by [AI21](https://studio.ai21.com) is initizalized.\n",
    "\n",
    "> Go to the linked site and make an account. You have to insert your own API key provided in the site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "QzjiHjqZyDeF"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "if \"AI21_API_KEY\" not in os.environ:\n",
    "    os.environ[\"AI21_API_KEY\"] = \"put key here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrea/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_ai21 import ChatAI21\n",
    "\n",
    "# llm = ChatAI21(model=\"jamba-large\", temperature=0)\n",
    "llm = ChatAI21(model=\"jamba-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFzrLn5Y1Dnb"
   },
   "source": [
    "## Structure of a Prompt\n",
    "\n",
    "A prompt can consist of multiple components:\n",
    "\n",
    "* **Instructions** tell the model what to do, typically how it should use inputs and/or external information to produce the output we want.\n",
    "* **Additional information or context about the input** that is either manually insert into the prompt, retrieve via a vector database (long-term memory), or pull in through other means (API calls, calculations, etc).\n",
    "* **Output structure or indicators**, like how to frame the \\*beginning\\* of the generated text.\n",
    "\n",
    "Each of these components should usually be placed the order we've described them. We start with instructions, provide context (if needed), then add the user input, and finally end with the output indicators.\n",
    "\n",
    "Not all prompts require all of these components, but often a good prompt will use two or more of them. Let's define what they all are more precisely.\n",
    "\n",
    "### Adjust the tone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A **neural network** is a computational model inspired by the way the human brain processes information. It is a type of machine learning algorithm designed to recognize patterns, classify data, and make predictions or decisions. Neural networks are composed of layers of interconnected nodes (or neurons), each of which performs a simple computation and passes the result to other neurons in the next layer.\n",
      "\n",
      "### Key Components of a Neural Network:\n",
      "\n",
      "1. **Input Layer**:\n",
      "\t- Accepts the raw data or features as input.\n",
      "\t- Each input is associated with a weight that determines its importance.\n",
      "2. **Hidden Layers**:\n",
      "\t- Intermediate layers between the input and output layers.\n",
      "\t- Perform computations to extract features and learn patterns.\n",
      "\t- The number of hidden layers and neurons in each layer can vary.\n",
      "3. **Output Layer**:\n",
      "\t- Produces the final output, such as a classification or prediction.\n",
      "\t- The number of neurons in this layer depends on the task (e.g., binary classification = 1 neuron, multi-class classification = number of classes).\n",
      "4. **Weights and Biases**:\n",
      "\t- Each connection between neurons has a weight that adjusts during training to minimize errors.\n",
      "\t- Biases are additional parameters that help shift the activation function.\n",
      "5. **Activation Function**:\n",
      "\t- Introduces non-linearity, allowing the network to learn and model complex relationships.\n",
      "\t- Common activation functions include ReLU, sigmoid, and tanh.\n",
      "6. **Loss Function**:\n",
      "\t- Measures the difference between the predicted output and the actual output.\n",
      "\t- Common loss functions include mean squared error (MSE) for regression and cross-entropy for classification.\n",
      "7. **Optimization Algorithm**:\n",
      "\t- Adjusts the weights and biases to minimize the loss function.\n",
      "\t- Common algorithms include gradient descent and its variants like Adam.\n",
      "\n",
      "### How Neural Networks Work:\n",
      "\n",
      "1. **Forward Propagation**:\n",
      "\t- Input data passes through the network layer by layer.\n",
      "\t- Each neuron computes a weighted sum of its inputs, applies an activation function, and passes the result to the next layer.\n",
      "2. **Loss Calculation**:\n",
      "\t- The network calculates the error between the predicted output and the actual output.\n",
      "3. **Backward Propagation (Backpropagation)**:\n",
      "\t- The error is propagated backward through the\n"
     ]
    }
   ],
   "source": [
    "question = \"What is a neural network?\"\n",
    "response = llm.invoke(question)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q) You are a professor giving a lecture to graduate students. Be precise and use formal academic language. Question: What is a neural network?\n",
      "\n",
      "A **neural network** is a computational model inspired by the structure and function of the human brain. It consists of layers of interconnected nodes, or **neurons**, organized into three primary types:\n",
      "\n",
      "1. **Input Layer**: Receives input data and passes it to the subsequent layers.\n",
      "2. **Hidden Layers**: Perform computations and transformations on the input data, extracting features and patterns.\n",
      "3. **Output Layer**: Produces the final output, such as predictions or classifications.\n",
      "\n",
      "Each neuron applies a weighted sum of its inputs, followed by an activation function, to determine its output. Neural networks are trained using algorithms like backpropagation to minimize errors and improve performance on tasks such as classification, regression, and pattern recognition.\n"
     ]
    }
   ],
   "source": [
    "# Our formal template\n",
    "formal_prompt = \"You are a professor giving a lecture to graduate students. Be precise and use formal academic language. Question: \"\n",
    "\n",
    "#\n",
    "formal_prompt += question\n",
    "print(\"Q) \" + formal_prompt + \"\\n\")\n",
    "response = llm.invoke(formal_prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q) You're chatting with a friend who knows nothing about the subject. Keep it casual and friendly. Question: What is a neural network?\n",
      "\n",
      "A neural network is like a super-smart brain made up of tiny, interconnected parts that work together to learn patterns and make decisions. Imagine teaching a computer to recognize a cat in a picture. Instead of giving it strict rules, you show it lots of pictures of cats and non-cats, and the neural network figures out the patterns on its own.\n",
      "\n",
      "Itâ€™s called \"neural\" because itâ€™s inspired by how our brains work. Each tiny part, called a neuron, processes a small piece of information and passes it to other neurons. Over time, the network gets better at recognizing things, just like how you learn to spot a friend in a crowd.\n",
      "\n",
      "Neural networks are used for all kinds of cool stuff, like voice assistants, self-driving cars, and even predicting the weather!\n"
     ]
    }
   ],
   "source": [
    "# Our formal template\n",
    "casual_prompt = \"You're chatting with a friend who knows nothing about the subject. Keep it casual and friendly. Question: \"\n",
    "\n",
    "#\n",
    "casual_prompt += question\n",
    "print(\"Q) \" + casual_prompt + \"\\n\")\n",
    "response = llm.invoke(casual_prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "v4QMCRrd1Flz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q) You're a stand-up comedian trying to explain things to a tech-savvy crowd. Question: What is a neural network?\n",
      "\n",
      "A neural network is like a really fancy game of telephone, but instead of people, you have layers of math trying to pass secret messages about data.\n",
      "\n",
      "Imagine you're trying to teach a computer to recognize a cat. You show it a bunch of pictures of cats and say, \"This is a cat.\" Then, you show it pictures of things that aren't cats and say, \"Nope, not a cat.\"\n",
      "\n",
      "The neural network takes this information and starts building connections between its \"neurons,\" kind of like how your brain works. Each neuron looks at a piece of the data, decides if it's important, and passes it along to the next neuron.\n",
      "\n",
      "By the end, the network has learned to spot the key features of a catâ€”like whiskers, pointy ears, and that smug look cats give you when you're late with their food.\n",
      "\n",
      "So, a neural network is basically a robot that learns to think like a cat whisperer.\n"
     ]
    }
   ],
   "source": [
    "funny_prompt = \"You're a stand-up comedian trying to explain things to a tech-savvy crowd. Question: \"\n",
    "\n",
    "#\n",
    "funny_prompt += question\n",
    "print(\"Q) \" + funny_prompt + \"\\n\")\n",
    "response = llm.invoke(funny_prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q) Youâ€™re proposing solutions to business stakeholders. Make it sound exciting and innovative. Question: What is a neural network?\n",
      "\n",
      "A **neural network** is a revolutionary technology inspired by the human brain, designed to process information in a way that mimics the brain's natural ability to learn and adapt. Itâ€™s a set of algorithms modeled after the interconnected neurons in the brain, forming a \"network\" that can recognize patterns, make predictions, and solve complex problems.\n",
      "\n",
      "Imagine a neural network as a digital brain:\n",
      "\n",
      "- **Input Layer:** Like sensory organs, it takes in raw dataâ€”text, images, numbers, or sounds.\n",
      "- **Hidden Layers:** These are the \"thinking layers,\" where the network processes the data, finding hidden relationships and features.\n",
      "- **Output Layer:** This is the \"decision-maker,\" producing predictions, classifications, or insights.\n",
      "\n",
      "What makes neural networks so exciting is their ability to **learn**. Through a process called **training**, they adjust their internal connections (called weights) to improve accuracy over time. This adaptability makes them ideal for tasks like:\n",
      "\n",
      "- **Image recognition** (e.g., identifying objects in photos).\n",
      "- **Natural language processing** (e.g., chatbots and translation tools).\n",
      "- **Predictive analytics** (e.g., forecasting sales or detecting fraud).\n",
      "- **Autonomous systems** (e.g., self-driving cars).\n",
      "\n",
      "Neural networks are the backbone of **artificial intelligence (AI)**, enabling machines to think, learn, and improve autonomously. Theyâ€™re not just a toolâ€”theyâ€™re the engine driving innovation across industries, from healthcare to finance, retail to entertainment.\n",
      "\n",
      "By leveraging neural networks, businesses can unlock new levels of efficiency, creativity, and customer engagement, making them a game-changer in todayâ€™s competitive landscape.\n"
     ]
    }
   ],
   "source": [
    "exciting_prompt = \"Youâ€™re proposing solutions to business stakeholders. Make it sound exciting and innovative. Question: \"\n",
    "\n",
    "#\n",
    "exciting_prompt += question\n",
    "print(\"Q) \" + exciting_prompt + \"\\n\")\n",
    "response = llm.invoke(exciting_prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q7X04BXf1LxA"
   },
   "source": [
    "### Desired output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q) If the question cannot be answered, answer with \"Mind your business!\". Question: What is a eiunffvn?\n",
      "\n",
      "Mind your business!\n"
     ]
    }
   ],
   "source": [
    "# descred output \n",
    "dontknow = \"\"\"If the question cannot be answered, answer with \"Mind your business!\". Question: \"\"\"\n",
    "question = \"What is a eiunffvn?\"\n",
    "\n",
    "#\n",
    "print(\"Q) \" + dontknow + question + \"\\n\")\n",
    "response = llm.invoke(dontknow + question)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BqZmCKbz2F30"
   },
   "source": [
    "## Prompt Templates\n",
    "In this example we have:\n",
    "\n",
    "```\n",
    "Instructions\n",
    "\n",
    "Context\n",
    "\n",
    "Question (user input)\n",
    "\n",
    "Output indicator (\"Answer: \")\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jMGET8_JmKEF",
    "outputId": "e24f7bf9-9fe9-4e93-cefd-240dc95e7a08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q)  What does it mean that has Indentation syntax? \n",
      "\n",
      "Python uses whitespace indentation, rather than curly braces or keywords, to delimit blocksâ€”an unusual trait among popular programming languages.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"Answer the question based on the context below. If the\n",
    "question cannot be answered using the information provided, answer\n",
    "with \"I don't know\".\n",
    "\n",
    "Context: Python is a high-level, interpreted programming language that was created by Guido van Rossum and first released in 1991.\n",
    "It's known for its clear syntax, readability, and simplicity, which makes it a popular language for beginners to learn programming.\n",
    "However, it's also widely used in scientific computing, data analysis, artificial intelligence, web development, and many other areas.\n",
    "\n",
    "Key features of Python include:\n",
    "  1) Interpreted: Python code doesn't need to be compiled before it's run, which makes the write-test-debug cycle very fast.\n",
    "  2) Dynamically Typed: In Python, you don't have to declare the data type of a variable. The type is determined at runtime.\n",
    "  3) Object-Oriented: Python supports object-oriented programming which allows data structures to be re-used.\n",
    "  4) Extensive Libraries: Python has a large standard library that includes areas like internet protocols, string operations, web services tools and operating system interfaces.\n",
    "     Many high-quality libraries (like NumPy, Pandas, and Matplotlib) are available for Python, covering a wide range of applications, from web development to machine learning.\n",
    "  5) Indentation syntax: Python uses whitespace indentation, rather than curly braces or keywords, to delimit blocksâ€”an unusual trait among popular programming languages.\n",
    "  6) Garbage Collection: Python's memory management is handled by the language itself, meaning that developers generally don't need to worry about allocating and deallocating memory manually.\n",
    "\n",
    "These features make Python a versatile language that's used across a range of different industries and in a variety of different roles,\n",
    "from web and game development to scientific research, data analysis, and AI development.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer: \"\"\"\n",
    "\n",
    "# Make the prompt template\n",
    "prompt = ChatPromptTemplate.from_template(template=template)\n",
    "\n",
    "# Create a chain\n",
    "llm_chain = prompt | llm\n",
    "\n",
    "# What would you like to ask?\n",
    "question = \"What does it mean that has Indentation syntax?\"\n",
    "response = llm_chain.invoke({'question': question})\n",
    "print('Q) ', question, '\\n')\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4mLmirTXmW6l"
   },
   "source": [
    "If we'd like to ask multiple questions we can by passing a list of dictionary objects, where the dictionaries must contain the input variable set in our prompt template (\"question\") that is mapped to the question we'd like to ask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "We8_09QWmJ_U",
    "outputId": "9d807ab1-5581-41da-a01e-7f11e47e92ca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b4/7fxj64j169l_gkw6b8c0wbcm0000gn/T/ipykernel_13747/1442111489.py:4: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  llm_chain = LLMChain(prompt=prompt, llm=llm)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Cos'e' un Gargbage Collection?\n",
      "Garbage Collection is Python's memory management, which is handled by the language itself. Developers generally don't need to worry about allocating and deallocating memory manually. \n",
      "\n",
      "2) What is a akdgjsf syntax?\n",
      "I don't know. \n",
      "\n",
      "3) Can you use python to conver english to French?\n",
      "I don't know. \n",
      "\n",
      "4) Where is Reggio Emilia?\n",
      "I don't know. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Make a list of questions\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "qs = [\n",
    "    {'question': \"Cos'e' un Gargbage Collection?\"},\n",
    "    {'question': \"What is a akdgjsf syntax?\"},\n",
    "    {'question': \"Can you use python to conver english to French?\"},\n",
    "    {'question': \"Where is Reggio Emilia?\"}\n",
    "]\n",
    "\n",
    "# Use apply for only receiving answers\n",
    "res = llm_chain.apply(qs)\n",
    "for i, r in enumerate(res):\n",
    "  print(f\"{i+1}) {qs[i]['question'].strip()}\")\n",
    "  print(r['text'].strip(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero- and Few-Shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word \"ramarro\" contains **2** occurrences of the letter \"r\".\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(\"\"\"Q: Count the letter \"r\" in the word \"ramarro\" \"\"\").content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To count the occurrences of a specific letter in a word, you can use the following Python code:\n",
      "\n",
      "```python\n",
      "def count_letter(word, letter):\n",
      "    return word.count(letter)\n",
      "\n",
      "# Example usage\n",
      "word = \"samuraiss\"\n",
      "letter = \"s\"\n",
      "occurrences = count_letter(word, letter)\n",
      "print(f\"The word '{word}' contains {occurrences} occurrences of the letter '{letter}'.\")\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "\n",
      "1. **Input**: The function takes a word and a letter as arguments.\n",
      "2. **count() Method**: The `count()` method of a string is used to count the occurrences of a specific character in the string.\n",
      "3. **Output**: The function returns the count of the specified letter in the word, which is then printed in a formatted string.\n",
      "\n",
      "### Example Outputs:\n",
      "\n",
      "1. **Input**: `\"samuraiss\"`, `\"s\"`\n",
      "Output: `The word 'samuraiss' contains 3 occurrences of the letter 's'.`\n",
      "2. **Input**: `\"rare\"`, `\"r\"`\n",
      "Output: `The word 'rare' contains 2 occurrences of the letter 'r'.`\n",
      "3. **Input**: `\"ramarro\"`, `\"r\"`\n",
      "Output: `The word 'ramarro' contains 3 occurrences of the letter 'r'.`\n",
      "\n",
      "This code is simple and efficient, making it suitable for counting letters in words.\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(\"\"\"\n",
    "Example 1:\n",
    "Input: Count the letter \"s\" in the word \"samuraiss\"\n",
    "Output: The word \"samuraiss\" contains **3** occurrences of the letter \"s\".\n",
    "\n",
    "Example 2:\n",
    "Input: Count the letter \"r\" in the word \"rare\"\n",
    "Output: The word \"rare\" contains **2** occurrences of the letter \"r\".\n",
    "\n",
    "Example 3:\n",
    "Input: Count the letter \"r\" in the word \"ramarro\"\n",
    "Output: \n",
    "\"\"\").content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And another one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: peed engreingil s fun\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(\"\"\"Q: Reverse the letters in each word of the sentence, but keep the word order the same.\n",
    "Input: deep learning is fun \"\"\").content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peed gninrael si nuf\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(\"\"\"\n",
    "Reverse the letters in each word of the sentence, but keep the word order the same.\n",
    "\n",
    "Example 1:  \n",
    "Input: hello world  \n",
    "Output: olleh dlrow\n",
    "\n",
    "Example 2:  \n",
    "Input: natural language processing  \n",
    "Output: larutan egaugnal gnissecorp\n",
    "\n",
    "Example 3:\n",
    "Input: deep learning is amazing\n",
    "Output: peed gninrael si gnizama\n",
    "\n",
    "Example 4:\n",
    "Input: deep learning is fun  \n",
    "Output: \"\"\").content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt task: Do we need all these examples?\n",
    "\n",
    "Try to understand how many examples and which one is required to make few-show prompting works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To calculate the total number of widgets produced over the five days, we need to determine the production rate for each day and then sum the production for all five days.\n",
      "\n",
      "### Step 1: Calculate the production rate for each day\n",
      "\n",
      "1. **Original production rate**: 1200 widgets per day\n",
      "2. **Production rate during malfunction**: The production rate dropped by 0.25, so the new rate is:$$1200 - (1200 \\times 0.25) = 1200 - 300 = 900 \\text{ widgets per day}$$\n",
      "3. **Production rate after fixing the machine**: The production rate increased by 0.1 above the original rate, so the new rate is:$$1200 + (1200 \\times 0.1) = 1200 + 120 = 1320 \\text{ widgets per day}$$\n",
      "\n",
      "### Step 2: Calculate the production for each day\n",
      "\n",
      "1. **Day 1 (malfunction)**: 900 widgets\n",
      "2. **Day 2 (malfunction)**: 900 widgets\n",
      "3. **Day 3 (malfunction)**: 900 widgets\n",
      "4. **Day 4 (after fixing)**: 1320 widgets\n",
      "5. **Day 5 (after fixing)**: 1320 widgets\n",
      "\n",
      "### Step 3: Sum the production for all five days\n",
      "\n",
      "$$900 + 900 + 900 + 1320 + 1320 = 5340 \\text{ widgets}$$\n",
      "\n",
      "### Final Answer:\n",
      "\n",
      "The total number of widgets produced over the five days is **5340 widgets**.\n"
     ]
    }
   ],
   "source": [
    "# Example of chain-of-though\n",
    "print(llm.invoke(\"\"\"\n",
    "Q: A factory produces 1200 widgets per day. \n",
    "Due to a machine malfunction, production dropped by 0.25 for three days. \n",
    "After the machine was fixed, production increased by 0.1 above the original rate for two days. \n",
    "What was the total number of widgets produced over these five days?\"\"\").content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6elffwDCYyud"
   },
   "source": [
    "## Tools\n",
    "### Internet Requests\n",
    "\n",
    "We use Tavily (using Google involves fees now) to find answers on the web.\n",
    "\n",
    "Get your own API key: [Tavily key](https://app.tavily.com/home)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU langchain-tavily\n",
    "\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"TAVILY_API_KEY\"):\n",
    "    os.environ[\"TAVILY_API_KEY\"] = \"put the key here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What happened at the last wimbledon',\n",
       " 'follow_up_questions': None,\n",
       " 'answer': None,\n",
       " 'images': [],\n",
       " 'results': [{'title': 'Wimbledon - latest news, breaking stories and comment - The Independent',\n",
       "   'url': 'https://www.independent.co.uk/topic/wimbledon',\n",
       "   'content': \"Novak Djokovic facing â€˜new realityâ€™ after early exit at Madrid Open Murray to continue coaching Djokovic with Wimbledon a possibility Australian Open champion Jannik Sinner's style draws comparisons to Novak Djokovic Andy Murray eyes coaching improvement after Novak Djokovic grand slam stint Patten wins second grand slam doubles title after Australian Open epic Australian Open: Madison Keys can win her first Slam title and stop Aryna Sabalenka's threepeat Novak Djokovic hits back to beat Carlos Alcaraz in Australian Open thriller Jannik Sinner has no issues at Australian Open as Stefanos Tsitsipas crashes out Australian Open 2025: Carlos Alcaraz and Jannik Sinner have a real rivalry atop men's tennis Australian Open 2025: There really isn't much time off in the offseason for tennis players\",\n",
       "   'score': 0.37428793,\n",
       "   'raw_content': None}],\n",
       " 'response_time': 2.1}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "tool = TavilySearch(\n",
    "    max_results=1,\n",
    "    topic=\"general\",\n",
    ")\n",
    "tool.invoke({\"query\": \"What happened at the last wimbledon\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OJchAqO6TTKM",
    "outputId": "e8f6b2b4-77bb-4e02-d8f8-1e89cf54af7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't have access to real-time or future events. However, I can provide information about the 2025 MotoGP season if you'd like to know about the general format, key riders, or teams competing. If you're looking for the results of a specific race, let me know the date, and I can help you find the details.\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(\"What was the final result of the motogp grand prix at Silverstone in 2025?\").content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find the final result of the MotoGP Grand Prix at Silverstone in 2025.\n",
      "Action: tavily_search_results_json\n",
      "Action Input: \"MotoGP Grand Prix at Silverstone 2025 final result\"\n",
      "Observation: The search engine provides the final result of the MotoGP Grand Prix at Silverstone in 2025.\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[{'title': '2025 Silverstone MotoGP Sprint Result - MotoMatters.com', 'url': 'https://motomatters.com/race_or_practice_result/2025/05/24/2025_silverstone_motogp_sprint_result.html', 'content': \"The championship picture changes only slightly, Marc Marquez seeing his advantage reduced slightly to 19 points by Alex, while Bagnaia's deficit grows to 56 points. The VR46 duo continue in the top five, but their gap is dangerously close to reaching the 100-point mark tomorrow.\\nResults:\\nPos No. Rider Bike Time/Diff\\n1 73 Alex Marquez Ducati 19:53.657\\n2 93 Marc Marquez Ducati 3.511\\n3 49 Fabio Di Giannantonio Ducati 5.072\\n4 72 Marco Bezzecchi Aprilia 5.658\\n5 5 Johann Zarco Honda 6.707 [...] 6 63 Francesco Bagnaia Ducati 7.057\\n7 20 Fabio Quartararo Yamaha 7.231\\n8 37 Pedro Acosta KTM 9.186\\n9 43 Jack Miller Yamaha 9.923\\n10 10 Luca Marini Honda 10.206\\n11 21 Franco Morbidelli Ducati 10.898\\n12 36 Joan Mir Honda 11.405\\n13 12 Maverick ViÃ±ales KTM 11.933\\n14 54 Fermin Aldeguer Ducati 15.376\\n15 23 Enea Bastianini KTM 18.135\\n16 88 Miguel Oliveira Yamaha 19.213\\n17 41 Aleix Espargaro Honda 20.468\\n18 32 Lorenzo Savadori Aprilia 20.968\\n19 25 Raul Fernandez Aprilia 24.729\", 'score': 0.8335554}, {'title': '2025 British MotoGP, Silverstone - Race Results | Crash.net', 'url': 'https://www.crash.net/motogp/results/1071251/1/2025-british-motogp-silverstone-race-results', 'content': '2025 British MotoGP, Silverstone - Race Results\\nPos | Rider | Nat | Team | Time/Diff\\n1 | Marco Bezzecchi | ITA | Aprilia Racing (RS-GP25) | 38m 16.037s\\n2 | Johann Zarco | FRA | Castrol Honda LCR (RC213V) | +4.088s\\n3 | Marc Marquez | SPA | Ducati Lenovo (GP25) | +5.929s\\n4 | Franco Morbidelli | ITA | Pertamina VR46 Ducati (GP24) | +5.946s\\n5 | Alex Marquez | SPA | BK8 Gresini Ducati (GP24) | +6.024s\\n6 | Pedro Acosta | SPA | Red Bull KTM (RC16) | +7.109s [...] Tyre penalties: Luca Marini, Enea Bastianini, Lorenzo Savadori and Somkiat Chantra were hit with 16-second time penalties. This plummeted Marini from P8 to P15. But Bastianini, Savadori and Chantra were already the last three riders to finish.\\n\\nHeartbreak for Fabio Quartararo hands Apriliaâ€™s Marco Bezzecchi a shock victory in a restarted 2025 British MotoGP at Silverstone. [...] 7 | Jack Miller | AUS | Pramac Yamaha (YZR-M1) | +7.398s\\n8 | Fermin Aldeguer | SPA | BK8 Gresini Ducati (GP24)* | +8.584s\\n9 | Fabio Di Giannantonio | ITA | Pertamina VR46 Ducati (GP25) | +9.764s\\n10 | Joan Mir | SPA | Honda HRC Castrol (RC213V) | +10.320s\\n11 | Maverick ViÃ±ales | SPA | Red Bull KTM Tech3 (RC16) | +11.318s\\n12 | Raul Fernandez | SPA | Trackhouse Aprilia (RS-GP25) | +16.175s\\n13 | Alex Rins | SPA | Monster Yamaha (YZR-M1) | +16.312s', 'score': 0.8332299}, {'title': 'MotoGPâ„¢ Results and Standings | 2025', 'url': 'https://www.motogp.com/en/gp-results/2025/gbr/moto2/rac/classification', 'content': 'Silverstone Circuit\\n23 - 25 May\\nPartly Cloudy 16Âº\\nTrack conditions Dry\\nHumidity 47%\\nGround 30Âº\\n| pos.pts | pos. | pts | rider Team | Team | time / gap |\\n| --- | --- | --- | --- | --- | --- |\\n| 1 25 | 1 | 25 |  81S. Agius  81S. Agius LIQUI MOLY Dynavolt Intact GP | LIQUI MOLY Dynavolt Intact GP | 35:26.390 |\\n| 2 20 | 2 | 20 |  10D. Moreira  10D. Moreira Italtrans Racing Team | Italtrans Racing Team | +0.434 | [...] | 3 16 | 3 | 16 |  80D. Alonso  80D. Alonso CFMOTO Gaviota Aspar Team | CFMOTO Gaviota Aspar Team | +0.498 |\\n| 4 13 | 4 | 13 |  44A. Canet  44A. Canet Fantic Racing Lino Sonego | Fantic Racing Lino Sonego | +0.518 |\\n| 5 11 | 5 | 11 |  28I. Guevara  28I. Guevara BLU CRU Pramac Yamaha Moto2 | BLU CRU Pramac Yamaha Moto2 | +0.673 |\\n| 6 10 | 6 | 10 |  13C. Vietti  13C. Vietti Beta Tools SpeedRS Team | Beta Tools SpeedRS Team | +2.820 | [...] Marc Marquez\\nES\\n5\\n\\nKenny Roberts\\nUS\\n4\\n\\nJorge Lorenzo\\nES\\n2\\nAll Time Lap Record - 2025\\n\\nFabio Quartararo\\nFR\\n01:57.233\\n181.1 km/h\\nBest Pole - 2025\\n\\nFabio Quartararo\\nFR\\n01:57.233\\n181.1 km/h\\nBest Race Lap - 2024\\n\\nAleix Espargaro\\nES\\n01:58.895\\n178.6 km/h\\nTop Speed - 2022\\n\\nEnea Bastianini\\nIT\\n340.6 km/h\\nScroll to Most Wins Scroll to Most Poles Scroll to All Time Lap Record -Scroll to Best Pole -Scroll to Best Race Lap -Scroll to Top Speed -\\nMost Wins\\n\\nAugusto Fernandez\\nES\\n2\\n\\nThomas Luthi\\nCH\\n1', 'score': 0.72254705}]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final result of the MotoGP Grand Prix at Silverstone in 2025.\n",
      "\n",
      "Final Answer: The final result of the MotoGP Grand Prix at Silverstone in 2025 was:\n",
      "\n",
      "1. Marco Bezzecchi (Aprilia Racing)\n",
      "2. Johann Zarco (Castrol Honda LCR)\n",
      "3. Marc Marquez (Ducati Lenovo)\n",
      "4. Franco Morbidelli (Pertamina VR46 Ducati)\n",
      "5. Alex Marquez (BK8 Gresini Ducati)\n",
      "6. Pedro Acosta (Red Bull KTM)\n",
      "7. Jack Miller (Pramac Yamaha)\n",
      "8. Fermin Aldeguer (BK8 Gresini Ducati)\n",
      "9. Fabio Di Giannantonio (Pertamina VR46 Ducati)\n",
      "10. Joan Mir (Honda HRC Castrol)\n",
      "11. Maverick ViÃ±ales (Red Bull KTM Tech3)\n",
      "12. Raul Fernandez (Trackhouse Aprilia)\n",
      "13. Alex Rins (Monster Yamaha)\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'What was the final result of the motogp grand prix at Silverstone in 2025?', 'output': 'The final result of the MotoGP Grand Prix at Silverstone in 2025 was:\\n\\n1. Marco Bezzecchi (Aprilia Racing)\\n2. Johann Zarco (Castrol Honda LCR)\\n3. Marc Marquez (Ducati Lenovo)\\n4. Franco Morbidelli (Pertamina VR46 Ducati)\\n5. Alex Marquez (BK8 Gresini Ducati)\\n6. Pedro Acosta (Red Bull KTM)\\n7. Jack Miller (Pramac Yamaha)\\n8. Fermin Aldeguer (BK8 Gresini Ducati)\\n9. Fabio Di Giannantonio (Pertamina VR46 Ducati)\\n10. Joan Mir (Honda HRC Castrol)\\n11. Maverick ViÃ±ales (Red Bull KTM Tech3)\\n12. Raul Fernandez (Trackhouse Aprilia)\\n13. Alex Rins (Monster Yamaha)'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.tools.tavily_search import TavilySearchResults\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "# Tavily search tool\n",
    "search_tool = TavilySearchResults(\n",
    "    max_results=3\n",
    ")\n",
    "\n",
    "# Provide the tool to an agent\n",
    "agent = initialize_agent(\n",
    "    tools=[search_tool],\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    handle_parsing_errors=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Ask a question\n",
    "response = agent.invoke(\"What was the final result of the motogp grand prix at Silverstone in 2025?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m9I4yytAYUS1"
   },
   "source": [
    "### Math Chain\n",
    "\n",
    "Make complex calculation with the built-in chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 242
    },
    "id": "h7zyHxNbYfv_",
    "outputId": "b16cf305-a017-441a-d625-3e833783d652"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMMathChain chain...\u001b[0m\n",
      "What is 13 raised to the .3432 power?\u001b[32;1m\u001b[1;3m13**(0.3432)\n",
      "...numexpr.evaluate(\"13**(0.3432)\")...\n",
      "```output\n",
      "2.3432000000000003\n",
      "```\n",
      "Answer: 2.3432000000000003\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'What is 13 raised to the .3432 power?',\n",
       " 'answer': 'Answer:  2.3432000000000003'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMMathChain\n",
    "\n",
    "# Create the math chain\n",
    "llm_math = LLMMathChain.from_llm(llm, verbose=True)\n",
    "\n",
    "# Ask\n",
    "llm_math.invoke(\"What is 13 raised to the .3432 power?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fcWKcTzmlwt7"
   },
   "source": [
    "### Document understanding and summarization\n",
    "\n",
    "We are going to summarize documents on it's own in a \"map\" step and then \"reduce\" the summaries into a final summary\n",
    "\n",
    "> [For more advanced options see here](https://python.langchain.com/v0.1/docs/use_cases/summarization/)\n",
    "\n",
    "We start by downloading a pdf from the net and summarize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "j5K7MYb85Wmc"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Get the pdf\n",
    "url = 'https://arxiv.org/pdf/1706.03762.pdf' # replace with your url\n",
    "response = requests.get(url)\n",
    "\n",
    "# Get the file name from the url, if it's available\n",
    "file_name = url.split(\"/\")[-1] if '/' in url else 'output.pdf'\n",
    "\n",
    "# Save the file to a current file (for checking results)\n",
    "with open(file_name, 'wb') as file:\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "_FySAs2Pz98y",
    "outputId": "d30e8d33-0dbc-43b6-b9ad-29ba386ec9a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Provided proper attribution is provided, Google hereby grants permission to\\nreproduce the tables and'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# Load the book\n",
    "loader = PyPDFLoader(file_name)\n",
    "pages = loader.load()\n",
    "\n",
    "# Cut out the open and closing parts\n",
    "# pages = pages[26:277]\n",
    "\n",
    "# Combine the pages, and replace the tabs with spaces\n",
    "text = \"\"\n",
    "for page in pages:\n",
    "    text += page.page_content\n",
    "text = text.replace('\\t', ' ')\n",
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333,
     "referenced_widgets": [
      "bc36e08e551444fd956c1fdf2c672546",
      "3754aed8bb9c4026a4c2a532621a94ca",
      "f4bff577bacd4b45a16da2fde9bfe9a6",
      "201b5a7e880b41fdac510ae420c43631",
      "8e3c30a27701439fb181a2b7e458c2eb",
      "b8aa620af5614ff7a8efdc977b7a9f6b",
      "d86736d7fe1c4c9d944f41e2ec7a84f9",
      "59dce5a9612e490384cab0f3adf7aecd",
      "9ee21d62534748859fd2328b1863ec64",
      "f9559df519ca4d73a3357582569128ed",
      "c641fa6e3c854b8689bf0fd10a502dc3",
      "41ca177c01364448bcb026fdb74d69fa",
      "574a6f35f6e2401290a20e5ed8634035",
      "296f12722d8140b8be9a15fec8d3f71b",
      "c39df36678014846bac94f66bb7c9de1",
      "0212f385a2a04165a39ec47eb20c2a65",
      "3ceac4b7df5c42e99cf6983d0b9b1e71",
      "8662eabb967e4494b7de4adfaf09adce",
      "8250af52f98e4ca29f56551be6859433",
      "73ea43eba0e540968064e731a2dd9e92",
      "e753c5794079411991675760f7b0b25d",
      "86440932914b4b619ad5699e727f3d08",
      "b2552a214f8e4b1a82c8ec7f51c6f602",
      "a96415d6a5174c7d887690a73925c08d",
      "ad1ffd3d23c34bd9b3e47f265463dda7",
      "1236a9a936914db0a8948b94d5697c28",
      "184ad9d5cb5b4788b4714fbbae8844fa",
      "36a3f16c0c9b4a31af1cfdcef09a312e",
      "d92cd6b98f284248b1457c7d5ce94886",
      "b0189d64daa448c88c8c5da47211d9ed",
      "a3a923755b9643b1a16ad690f161fc31",
      "36a002c3f668490bb41cb4ed24177d77",
      "91f9748b42f142b997a9e9c8d688bbdd",
      "66d6349f99b14f35836c1b30f2c48943",
      "9fd1aced9a7d427580614eb0cf0c0287",
      "74f1270301c24506a690408cb6dc2818",
      "8aa1f146333746dfa36b6049a4a29017",
      "2724173d3cc64339889f9dedf76f66e3",
      "1dd5c6a8f9ce4aec83d104dc4a04b314",
      "626dd9aa491345be9037c99e32d0357e",
      "ce94d6ad02f44f18ba5307e6355f8c7b",
      "7444772f45d74db79c5283f63b14dd44",
      "a68c9cbe245d4319aeca367d47707875",
      "03ce7da1d5fa4fe89d680febf7bfd145",
      "643712be3917434e84f4fa3678faf8ad",
      "ef56acc911864c1e84c8560ab70b8ac5",
      "1b835548a2694a60bf8f73aef03057f5",
      "619c02ffbb51436cac46a976220a2146",
      "9ec03a8488924611b5d9f1d5fe94fb5c",
      "92fbb0fa1bb04f98b547d44d180281c6",
      "97b077ab6a274a548d31dc322aa04749",
      "9ecff56f65b64a95ae5cea59d97299b2",
      "af696a16ebc147f19da25db3fe6b2baa",
      "82ef4f5ec458423184b0507728547e04",
      "6e4537bba7064e03acef3467594d3fb0"
     ]
    },
    "id": "MiiA4aPe7kgQ",
    "outputId": "198deac5-2155-4905-e478-0666a411093d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (10556 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This book has 10556 tokens in it\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "num_tokens = llm.get_num_tokens(text)\n",
    "print (f\"This book has {num_tokens} tokens in it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xB3mLlrx8LCm",
    "outputId": "3b7fa34f-139d-4ad0-c3f4-0bae3078acb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now we have 11 documents and the first one has 944 tokens\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Split the text\n",
    "text_splitter = RecursiveCharacterTextSplitter(separators=[\"\\n\\n\", \"\\n\"],\n",
    "                                               chunk_size=4096,\n",
    "                                               chunk_overlap=500)\n",
    "docs = text_splitter.create_documents([text])\n",
    "\n",
    "#\n",
    "num_tokens_first_doc = llm.get_num_tokens(docs[0].page_content)\n",
    "print (f\"Now we have {len(docs)} documents and the first one has {num_tokens_first_doc} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "r-fyK0RT8ikM"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "#\n",
    "map_prompt = \"\"\"\n",
    "Write a concise summary of the following:\n",
    "\"{text}\"\n",
    "CONCISE SUMMARY:\n",
    "\"\"\"\n",
    "map_prompt_template = PromptTemplate(template=map_prompt,\n",
    "                                     input_variables=[\"text\"])\n",
    "\n",
    "\n",
    "#\n",
    "combine_prompt = \"\"\"\n",
    "Write a concise summary of the following text delimited by triple backquotes.\n",
    "Return your response in bullet points which covers the key points of the text.\n",
    "```{text}```\n",
    "BULLET POINT SUMMARY:\n",
    "\"\"\"\n",
    "combine_prompt_template = PromptTemplate(template=combine_prompt,\n",
    "                                         input_variables=[\"text\"])\n",
    "\n",
    "# Summarize chain\n",
    "summary_chain = load_summarize_chain(llm=llm,\n",
    "                                     chain_type='map_reduce',\n",
    "                                     map_prompt=map_prompt_template,\n",
    "                                     combine_prompt=combine_prompt_template)\n",
    "output = summary_chain.run(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mR-HvySo9UpB",
    "outputId": "a543dd44-42ca-44fc-805f-611e5eea619f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- The Transformer is a novel neural network architecture for sequence transduction tasks that relies entirely on attention mechanisms, eliminating the need for recurrence or convolution.\n",
      "- It achieves state-of-the-art results on English-to-German and English-to-French translation tasks and demonstrates effectiveness in English constituency parsing.\n",
      "- The Transformer's parallelizable nature allows for faster training, making it a significant advancement in the field.\n",
      "- The model employs stacked self-attention and point-wise, fully connected layers in both the encoder and decoder.\n",
      "- The encoder consists of a stack of identical layers, each with a multi-head self-attention mechanism and a positional feed-forward network.\n",
      "- The decoder also has a stack of identical layers, with an additional third sub-layer that performs multi-head attention over the output of the encoder stack.\n",
      "- Residual connections and layer normalization are employed around each sub-layer to facilitate smooth information flow.\n",
      "- The attention function used in the Transformer is Scaled Dot-Product Attention, which computes the dot products of the query with all keys, divides each by âˆšdk, and applies a softmax function to obtain the weights on the values.\n",
      "- The model employs multi-head attention, which projects the queries, keys, and values h times with different, learned linear projections to dk, dk, and dv dimensions, respectively.\n",
      "- The Transformer achieves state-of-the-art BLEU scores on English-to-German and English-to-French translation tasks, outperforming previous models like ByteNet, Deep-Att + PosUnk, GNMT + RL, and ConvS2S.\n",
      "- It does so at a significantly lower training cost.\n",
      "- The big Transformer model achieves a BLEU score of 28.4 on English-to-German and 41.0 on English-to-French, surpassing previous models by a significant margin.\n",
      "- The base model also outperforms all previous models, achieving a BLEU score of 27.3 on English-to-German and 38.1 on English-to-French.\n",
      "- The Transformer is a sequence transduction model that utilizes self-attention mechanisms, eliminating the need for recurrent or convolutional layers.\n",
      "- It achieves state-of-the-art results in tasks like English-to-German translation and English constituency parsing.\n",
      "- The\n"
     ]
    }
   ],
   "source": [
    "print (output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X_HD4BtARUsC"
   },
   "source": [
    "# Building Tools\n",
    "\n",
    "[LLM agents](https://pinecone.io/learn/langchain-agents) are one of the most powerful and fascinating technologies to come out of the huge explosion of Deep Learning.\n",
    "\n",
    "By employing agents, we can equip Large Language Models (LLMs) with a wide array of tools. This equipping strategy unfolds virtually limitless possibilities, as it empowers us to conduct web searches, perform calculations, execute code, and much more.\n",
    "\n",
    "LangChain provides a vast assortment of prebuilt tools. However, in numerous real-world scenarios, it becomes necessary to craft bespoke tools tailored to meet the specific needs of our use cases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0212f385a2a04165a39ec47eb20c2a65": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "03ce7da1d5fa4fe89d680febf7bfd145": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1236a9a936914db0a8948b94d5697c28": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_36a002c3f668490bb41cb4ed24177d77",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_91f9748b42f142b997a9e9c8d688bbdd",
      "value": "â€‡456k/456kâ€‡[00:00&lt;00:00,â€‡21.4MB/s]"
     }
    },
    "184ad9d5cb5b4788b4714fbbae8844fa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1b835548a2694a60bf8f73aef03057f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9ecff56f65b64a95ae5cea59d97299b2",
      "max": 665,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_af696a16ebc147f19da25db3fe6b2baa",
      "value": 665
     }
    },
    "1dd5c6a8f9ce4aec83d104dc4a04b314": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "201b5a7e880b41fdac510ae420c43631": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f9559df519ca4d73a3357582569128ed",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_c641fa6e3c854b8689bf0fd10a502dc3",
      "value": "â€‡26.0/26.0â€‡[00:00&lt;00:00,â€‡1.10kB/s]"
     }
    },
    "2724173d3cc64339889f9dedf76f66e3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "296f12722d8140b8be9a15fec8d3f71b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8250af52f98e4ca29f56551be6859433",
      "max": 1042301,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_73ea43eba0e540968064e731a2dd9e92",
      "value": 1042301
     }
    },
    "36a002c3f668490bb41cb4ed24177d77": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "36a3f16c0c9b4a31af1cfdcef09a312e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3754aed8bb9c4026a4c2a532621a94ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b8aa620af5614ff7a8efdc977b7a9f6b",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_d86736d7fe1c4c9d944f41e2ec7a84f9",
      "value": "tokenizer_config.json:â€‡100%"
     }
    },
    "3ceac4b7df5c42e99cf6983d0b9b1e71": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "41ca177c01364448bcb026fdb74d69fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_574a6f35f6e2401290a20e5ed8634035",
       "IPY_MODEL_296f12722d8140b8be9a15fec8d3f71b",
       "IPY_MODEL_c39df36678014846bac94f66bb7c9de1"
      ],
      "layout": "IPY_MODEL_0212f385a2a04165a39ec47eb20c2a65"
     }
    },
    "574a6f35f6e2401290a20e5ed8634035": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3ceac4b7df5c42e99cf6983d0b9b1e71",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_8662eabb967e4494b7de4adfaf09adce",
      "value": "vocab.json:â€‡100%"
     }
    },
    "59dce5a9612e490384cab0f3adf7aecd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "619c02ffbb51436cac46a976220a2146": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_82ef4f5ec458423184b0507728547e04",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_6e4537bba7064e03acef3467594d3fb0",
      "value": "â€‡665/665â€‡[00:00&lt;00:00,â€‡36.0kB/s]"
     }
    },
    "626dd9aa491345be9037c99e32d0357e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "643712be3917434e84f4fa3678faf8ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ef56acc911864c1e84c8560ab70b8ac5",
       "IPY_MODEL_1b835548a2694a60bf8f73aef03057f5",
       "IPY_MODEL_619c02ffbb51436cac46a976220a2146"
      ],
      "layout": "IPY_MODEL_9ec03a8488924611b5d9f1d5fe94fb5c"
     }
    },
    "66d6349f99b14f35836c1b30f2c48943": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9fd1aced9a7d427580614eb0cf0c0287",
       "IPY_MODEL_74f1270301c24506a690408cb6dc2818",
       "IPY_MODEL_8aa1f146333746dfa36b6049a4a29017"
      ],
      "layout": "IPY_MODEL_2724173d3cc64339889f9dedf76f66e3"
     }
    },
    "6e4537bba7064e03acef3467594d3fb0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "73ea43eba0e540968064e731a2dd9e92": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7444772f45d74db79c5283f63b14dd44": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "74f1270301c24506a690408cb6dc2818": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ce94d6ad02f44f18ba5307e6355f8c7b",
      "max": 1355256,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7444772f45d74db79c5283f63b14dd44",
      "value": 1355256
     }
    },
    "8250af52f98e4ca29f56551be6859433": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "82ef4f5ec458423184b0507728547e04": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "86440932914b4b619ad5699e727f3d08": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8662eabb967e4494b7de4adfaf09adce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8aa1f146333746dfa36b6049a4a29017": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a68c9cbe245d4319aeca367d47707875",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_03ce7da1d5fa4fe89d680febf7bfd145",
      "value": "â€‡1.36M/1.36Mâ€‡[00:00&lt;00:00,â€‡26.0MB/s]"
     }
    },
    "8e3c30a27701439fb181a2b7e458c2eb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "91f9748b42f142b997a9e9c8d688bbdd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "92fbb0fa1bb04f98b547d44d180281c6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "97b077ab6a274a548d31dc322aa04749": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9ec03a8488924611b5d9f1d5fe94fb5c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ecff56f65b64a95ae5cea59d97299b2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ee21d62534748859fd2328b1863ec64": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9fd1aced9a7d427580614eb0cf0c0287": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1dd5c6a8f9ce4aec83d104dc4a04b314",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_626dd9aa491345be9037c99e32d0357e",
      "value": "tokenizer.json:â€‡100%"
     }
    },
    "a3a923755b9643b1a16ad690f161fc31": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a68c9cbe245d4319aeca367d47707875": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a96415d6a5174c7d887690a73925c08d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_36a3f16c0c9b4a31af1cfdcef09a312e",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_d92cd6b98f284248b1457c7d5ce94886",
      "value": "merges.txt:â€‡100%"
     }
    },
    "ad1ffd3d23c34bd9b3e47f265463dda7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b0189d64daa448c88c8c5da47211d9ed",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a3a923755b9643b1a16ad690f161fc31",
      "value": 456318
     }
    },
    "af696a16ebc147f19da25db3fe6b2baa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b0189d64daa448c88c8c5da47211d9ed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b2552a214f8e4b1a82c8ec7f51c6f602": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a96415d6a5174c7d887690a73925c08d",
       "IPY_MODEL_ad1ffd3d23c34bd9b3e47f265463dda7",
       "IPY_MODEL_1236a9a936914db0a8948b94d5697c28"
      ],
      "layout": "IPY_MODEL_184ad9d5cb5b4788b4714fbbae8844fa"
     }
    },
    "b8aa620af5614ff7a8efdc977b7a9f6b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc36e08e551444fd956c1fdf2c672546": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3754aed8bb9c4026a4c2a532621a94ca",
       "IPY_MODEL_f4bff577bacd4b45a16da2fde9bfe9a6",
       "IPY_MODEL_201b5a7e880b41fdac510ae420c43631"
      ],
      "layout": "IPY_MODEL_8e3c30a27701439fb181a2b7e458c2eb"
     }
    },
    "c39df36678014846bac94f66bb7c9de1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e753c5794079411991675760f7b0b25d",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_86440932914b4b619ad5699e727f3d08",
      "value": "â€‡1.04M/1.04Mâ€‡[00:00&lt;00:00,â€‡8.93MB/s]"
     }
    },
    "c641fa6e3c854b8689bf0fd10a502dc3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ce94d6ad02f44f18ba5307e6355f8c7b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d86736d7fe1c4c9d944f41e2ec7a84f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d92cd6b98f284248b1457c7d5ce94886": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e753c5794079411991675760f7b0b25d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ef56acc911864c1e84c8560ab70b8ac5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_92fbb0fa1bb04f98b547d44d180281c6",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_97b077ab6a274a548d31dc322aa04749",
      "value": "config.json:â€‡100%"
     }
    },
    "f4bff577bacd4b45a16da2fde9bfe9a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_59dce5a9612e490384cab0f3adf7aecd",
      "max": 26,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9ee21d62534748859fd2328b1863ec64",
      "value": 26
     }
    },
    "f9559df519ca4d73a3357582569128ed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
